{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Libraries\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class deffinition to load dataset from directory\n",
    "\n",
    "class ImageDataLoader:\n",
    "        \n",
    "    def __init__(self, data_path, imageSize, num_channel, num_classes=10):\n",
    "        \n",
    "        self.train_images = []\n",
    "        self.train_labels = []\n",
    "\n",
    "        self.test_images = []\n",
    "        self.test_labels = []\n",
    "    \n",
    "        # Get the size of image and number of samples in each category\n",
    "        self.data_path = data_path # List of data directories ['root/../train/', 'root/../test/']\n",
    "                \n",
    "        self.imageSize = imageSize\n",
    "        self.num_channel = num_channel\n",
    "        \n",
    "    def call(self): # Function to hold all categories\n",
    "         # Train images along labels and Test images along labels\n",
    "        \n",
    "        x_train, x_valid, y_train, y_valid, self.train_cls, self.valid_cls = self.load_train()\n",
    "        \n",
    "        self.x_test, self.y_test = self.load_test()\n",
    "        \n",
    "        # Split and normalized the training set into train and validation\n",
    "        self.x_train = x_train / 255.0\n",
    "        self.x_valid = x_valid / 255.0\n",
    "        \n",
    "        self.y_train = y_train\n",
    "        self.y_valid = y_valid\n",
    "        \n",
    "        # Convert class-numbers to integer\n",
    "        self.y_train = self.y_train.astype(np.int)\n",
    "        self.y_test = self.y_test.astype(np.int)\n",
    "        self.y_valid = self.y_valid.astype(np.int)\n",
    "\n",
    "    # Function to read train image data from directory\n",
    "    def read_train_data_from_dir(self):\n",
    "        print(\"\\n================================= Loading Train Images ===============================\\n\")\n",
    "        for data in sorted(os.listdir(self.data_path[0])):\n",
    "\n",
    "            for img in sorted(os.listdir(os.path.join(self.data_path[0], data))):\n",
    "                \n",
    "                image = cv2.imread(os.path.join(self.data_path[0], data, img), self.num_channel)\n",
    "                image = cv2.resize(image, (self.imageSize, self.imageSize))\n",
    "\n",
    "                self.train_images.append((np.array(image, dtype=np.uint8)))\n",
    "                self.train_labels.append(int(data))  # name of the data_dir must be labeled in number (e.g 0, 1, 2 ..)\n",
    "\n",
    "            print(\"Reading and Loading Train images from: %s\" % os.path.join(self.data_path[0], data))\n",
    "\n",
    "        return self.train_images, self.train_labels\n",
    "\n",
    "    # Function to read test image data from directory\n",
    "    def read_test_data_from_dir(self):\n",
    "        print(\"\\n================================= Loading Test Images ===============================\\n\")\n",
    "        for data in sorted(os.listdir(self.data_path[1])):\n",
    "\n",
    "            for img in sorted(os.listdir(os.path.join(self.data_path[1], data))):\n",
    "\n",
    "                image = cv2.imread(os.path.join(self.data_path[1], data, img), self.num_channel)\n",
    "                image = cv2.resize(image, (self.imageSize, self.imageSize))\n",
    "\n",
    "                self.test_images.append((np.array(image, dtype=np.uint8)))\n",
    "                self.test_labels.append(int(data))  # name of the data_dir must be labeled in number (e.g 0, 1, 2 ..)\n",
    "\n",
    "            print(\"Reading and Loading Test images from: %s\" % os.path.join(self.data_path[1], data))\n",
    "\n",
    "        return self.test_images, self.test_labels\n",
    "    \n",
    "    # Split training images into train and validation    \n",
    "    def load_train(self):\n",
    "        \n",
    "        tr_images, tr_labels = self.read_train_data_from_dir()\n",
    "            \n",
    "        # Convert list of images and labels into numpy array\n",
    "        tr_images = np.array(tr_images, dtype=np.float32)\n",
    "        tr_labels = np.array(tr_labels)\n",
    "\n",
    "        # One-hot encoding \n",
    "        Y = np_utils.to_categorical(tr_labels)\n",
    "        \n",
    "        # Shuffling \n",
    "        X, y = shuffle(tr_images, Y, random_state=4)\n",
    "        x_train_cls, y_valid_cls = shuffle(tr_images, tr_labels, random_state=4)\n",
    "        \n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(X, y, stratify=None, test_size=0.2, random_state=4)\n",
    "        train_img1, test_img1, train_cls, valid_cls = train_test_split(x_train_cls, y_valid_cls, stratify=None, test_size=0.3, random_state=2)\n",
    "\n",
    "        # Here ignore the train_img1 and test_img1, just take the non-one_hot_encoded version of y_train and y_valid\n",
    "        return x_train, x_valid, y_train, y_valid, train_cls, valid_cls\n",
    "    \n",
    "    # Normalizing Test images\n",
    "    def load_test(self):\n",
    "        \n",
    "        tst_images, tst_labels = self.read_test_data_from_dir()\n",
    "            \n",
    "        # Convert list of images and labels into numpy array\n",
    "        tst_images = np.array(tst_images, dtype=np.float64) / 255.0\n",
    "        tst_labels = np.array(tst_labels)\n",
    "\n",
    "        # One-hot encoding \n",
    "        Y = np_utils.to_categorical(tst_labels)\n",
    "        \n",
    "        # Shuffling \n",
    "        X, y = shuffle(tst_images, Y, random_state=4)\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "    def random_batch(self, images, labels, batch_size=32):\n",
    "        \n",
    "        # Create a random index into the training set\n",
    "        indx = np.random.randint(low=0, high=int(len(images)), size=batch_size)\n",
    "        \n",
    "        # Use the index to lookup random training data\n",
    "        x_batch = images[indx]\n",
    "        y_batch = labels[indx]\n",
    "        \n",
    "        return x_batch, y_batch\n",
    "    \n",
    "    def pickle_data(self):\n",
    "        \n",
    "        print(\"[INFO] Saving image data to disk...\\n\")\n",
    "        with open('x_train', 'wb') as f:\n",
    "            pickle.dump(self.x_train, f)\n",
    "#             del self.x_train\n",
    "        with open('y_train', 'wb') as f:\n",
    "            pickle.dump(self.y_train, f)\n",
    "#             del self.y_train\n",
    "        with open('x_valid', 'wb') as f:\n",
    "            pickle.dump(self.x_valid, f)\n",
    "#             del self.x_valid\n",
    "        with open('y_valid', 'wb') as f:\n",
    "            pickle.dump(self.y_valid, f)\n",
    "#             del self.y_valid\n",
    "        with open('x_test', 'wb') as f:\n",
    "            pickle.dump(self.x_test, f)\n",
    "#             del self.x_test\n",
    "        with open('y_test', 'wb') as f:\n",
    "            pickle.dump(self.y_test, f)\n",
    "#             del self.y_test\n",
    "        with open('array/x_train_cls', 'wb') as f:\n",
    "            pickle.dump(self.train_cls, f)\n",
    "#             del train_cls\n",
    "        with open('array/y_test_cls', 'wb') as f:\n",
    "            pickle.dump(self.valid_cls, f)\n",
    "#             del test_cls\n",
    "        print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = [os.path.join(os.getcwd(), 'data', 'train'), os.path.join(os.getcwd(), 'data', 'test')]\n",
    "imageSize = 120\n",
    "num_channel = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataLoader(data_path, imageSize, num_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================= Loading Train Images ===============================\n",
      "\n",
      "Reading and Loading Train images from: C:\\Users\\Lord Sanmilee\\Desktop\\git\\data\\train\\0\n",
      "Reading and Loading Train images from: C:\\Users\\Lord Sanmilee\\Desktop\\git\\data\\train\\1\n",
      "Reading and Loading Train images from: C:\\Users\\Lord Sanmilee\\Desktop\\git\\data\\train\\2\n",
      "Reading and Loading Train images from: C:\\Users\\Lord Sanmilee\\Desktop\\git\\data\\train\\3\n",
      "Reading and Loading Train images from: C:\\Users\\Lord Sanmilee\\Desktop\\git\\data\\train\\4\n",
      "Reading and Loading Train images from: C:\\Users\\Lord Sanmilee\\Desktop\\git\\data\\train\\5\n",
      "Reading and Loading Train images from: C:\\Users\\Lord Sanmilee\\Desktop\\git\\data\\train\\6\n",
      "Reading and Loading Train images from: C:\\Users\\Lord Sanmilee\\Desktop\\git\\data\\train\\7\n",
      "Reading and Loading Train images from: C:\\Users\\Lord Sanmilee\\Desktop\\git\\data\\train\\8\n",
      "Reading and Loading Train images from: C:\\Users\\Lord Sanmilee\\Desktop\\git\\data\\train\\9\n",
      "\n",
      "================================= Loading Test Images ===============================\n",
      "\n",
      "Reading and Loading Test images from: C:\\Users\\Lord Sanmilee\\Desktop\\git\\data\\test\\0\n",
      "Reading and Loading Test images from: C:\\Users\\Lord Sanmilee\\Desktop\\git\\data\\test\\1\n",
      "Reading and Loading Test images from: C:\\Users\\Lord Sanmilee\\Desktop\\git\\data\\test\\2\n",
      "Reading and Loading Test images from: C:\\Users\\Lord Sanmilee\\Desktop\\git\\data\\test\\3\n",
      "Reading and Loading Test images from: C:\\Users\\Lord Sanmilee\\Desktop\\git\\data\\test\\4\n",
      "Reading and Loading Test images from: C:\\Users\\Lord Sanmilee\\Desktop\\git\\data\\test\\5\n",
      "Reading and Loading Test images from: C:\\Users\\Lord Sanmilee\\Desktop\\git\\data\\test\\6\n",
      "Reading and Loading Test images from: C:\\Users\\Lord Sanmilee\\Desktop\\git\\data\\test\\7\n",
      "Reading and Loading Test images from: C:\\Users\\Lord Sanmilee\\Desktop\\git\\data\\test\\8\n",
      "Reading and Loading Test images from: C:\\Users\\Lord Sanmilee\\Desktop\\git\\data\\test\\9\n"
     ]
    }
   ],
   "source": [
    "data.call()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 120, 120)\n",
      "(10000, 120, 120)\n",
      "(12500, 120, 120) \n",
      "\n",
      "(40000, 10)\n",
      "(10000, 10)\n",
      "(12500, 10) \n",
      "\n",
      "(100, 120, 120)\n",
      "(100, 120, 120)\n",
      "(100, 120, 120) \n",
      "\n",
      "(35000,)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "print(data.x_train.shape)\n",
    "print(data.x_valid.shape)\n",
    "print(data.x_test.shape, \"\\n\")\n",
    "\n",
    "print(data.y_train.shape)\n",
    "print(data.y_valid.shape)\n",
    "print(data.y_test.shape, \"\\n\")\n",
    "\n",
    "print(data.random_batch(data.x_train, data.y_train, 100)[0].shape)\n",
    "print(data.random_batch(data.x_valid, data.y_valid, 100)[0].shape)\n",
    "print(data.random_batch(data.x_test, data.y_test, 100)[0].shape, \"\\n\")\n",
    "\n",
    "print(data.train_cls.shape)\n",
    "print(data.valid_cls.shape)\n",
    "\n",
    "#print(data.train_cls)\n",
    "#print(data.valid_cls)\n",
    "\n",
    "#print(data.y_test)\n",
    "#print(data.y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving image data to disk...\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "data.pickle_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 120, 120)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data.random_batch(data.x_train, data.y_train, 100)[0].shape\n",
    "# batch[1].shape\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
